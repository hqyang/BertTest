# History
This is a practice to test BERT for Chinese Word Segmentation task.

## Test classifier
python run_classifier_torch.py

## Test Chinese Word Segmentation with BERT
python main.py

### Input format for the Ontonotes dataset
*   bert_ner	bert_seg	full_pos	src_ner	src_seg	text	text_seg
>  An example
>      s = '(NP (CP (IP (NP (DNP (NER-GPE (NR Taiwan)) (DEG çš„)) (NER-ORG (NR å…¬è§†))) (VP (NT ä»Šå¤©) (VV ä¸»åŠž))) (DEC çš„)) (NP-m (NP (NR å°åŒ—) (NN å¸‚é•¿)) (NP-m (NP (NN candidate) (NN defence)) (PU ï¼Œ))))'
>      bert_ner: W-GPE O B-ORG E-ORG B E B E O B E B E B M M E B M E O
>      bert_seg: S S B E B E B E S B E B E B M M E B M E S
>      full_pos: (NP (CP (IP (NP (DNP (NR )NR )DNP (DEG )DEG )NP (NR )NR )IP )CP (VP (NT )NT (VV )VV )VP )NP (DEC )DEC )DEC (NP-m (NP (NR )NR (NN )NN )NP (NP-m (NP (NN )NN (NN )NN )NP (PU )PU )NP-m )NP-m )NP-m
>      src_ner: W-GPE,O,B-ORG,E-ORG,B,E,B,E,O,B,E,B,E,O,O,O,
>      src_seg: S,S,B,E,B,E,B,E,S,B,E,B,E,S,S,S,
>      text: Taiwançš„å…¬è§†ä»Šå¤©ä¸»åŠžçš„å°åŒ—å¸‚é•¿candidate defenceï¼Œ
>      text_seg: Taiwan çš„ å…¬è§† ä»Šå¤© ä¸»åŠž çš„ å°åŒ— å¸‚é•¿ candidate defence ï¼Œ

### Input format for the four CWS datasets: AS, CityU, MSR, PKU
*   bert_seg	full_pos	src_seg	text	text_seg
>  An example
>      s = 'ç›®å‰ã€€ç”±ã€€ï¼’ï¼“ï¼’ã€€ä½ã€€é™¢å£«ã€€ï¼ˆã€€ï¼¦ï½…ï½Œï½Œï½ï½—ã€€åŠã€€ï¼¦ï½ï½•ï½Žï½„ï½‰ï½Žï½‡ã€€ï¼¦ï½…ï½Œï½Œï½ï½—ã€€ï¼‰ã€€ï¼Œï¼–ï¼–ã€€ä½ã€€å”é™¢å£«ã€€ï¼ˆã€€ï¼¡ï½“ï½“ï½ï½ƒï½‰ï½ï½”ï½…ã€€ï¼¦ï½…ï½Œï½Œï½ï½—ã€€ï¼‰ã€€ï¼’ï¼”ã€€ä½ã€€é€šä¿¡ã€€é™¢å£«ã€€ï¼ˆã€€ï¼£ï½ï½’ï½’ï½…ï½“ï½ï½ï½Žï½„ï½‰ï½Žï½‡ã€€ï¼¦ï½…ï½Œï½Œï½ï½—ã€€ï¼‰ã€€åŠã€€ï¼’ã€€ä½ã€€é€šä¿¡ã€€å”é™¢å£«ã€€ï¼ˆã€€ï¼£ï½ï½’ï½’ï½…ï½“ï½ï½ï½Žï½„ï½‰ï½Žï½‡ã€€ï¼¡ï½“ï½“ï½ï½ƒï½‰ï½ï½”ï½…ã€€ï¼¦ï½…ï½Œï½Œï½ï½—ã€€ï¼‰ã€€çµ„æˆã€€ï¼ˆã€€ä¸ã€€åŒ…æ‹¬ã€€ä¸€ä¹ä¹å››å¹´ã€€ç•¶é¸ã€€è€…ã€€ï¼‰ã€€ï¼Œ'
>      bert_seg: S S B E B E B E S B E B E B M M E B M E S
>      src_seg: S,S,B,E,B,E,B,E,S,B,E,B,E,S,S,S,
>      text: ç›®å‰ç”±ï¼’ï¼“ï¼’ä½é™¢å£«ï¼ˆï¼¦ï½…ï½Œï½Œï½ï½—åŠï¼¦ï½ï½•ï½Žï½„ï½‰ï½Žï½‡ã€€ï¼¦ï½…ï½Œï½Œï½ï½—ï¼‰ï¼Œï¼–ï¼–ä½å”é™¢å£«ï¼ˆï¼¡ï½“ï½“ï½ï½ƒï½‰ï½ï½”ï½…ã€€ï¼¦ï½…ï½Œï½Œï½ï½—ï¼‰ï¼’ï¼”ä½é€šä¿¡é™¢å£«ï¼ˆï¼£ï½ï½’ï½’ï½…ï½“ï½ï½ï½Žï½„ï½‰ï½Žï½‡ã€€ï¼¦ï½…ï½Œï½Œï½ï½—ï¼‰åŠï¼’ä½é€šä¿¡å”é™¢å£«ï¼ˆï¼£ï½ï½’ï½’ï½…ï½“ï½ï½ï½Žï½„ï½‰ï½Žï½‡ã€€ï¼¡ï½“ï½“ï½ï½ƒï½‰ï½ï½”ï½…ã€€ï¼¦ï½…ï½Œï½Œï½ï½—ï¼‰çµ„æˆï¼ˆä¸åŒ…æ‹¬ä¸€ä¹ä¹å››å¹´ç•¶é¸è€…ï¼‰ï¼Œ
>      text_seg: ç›®å‰ã€€ç”±ã€€ï¼’ï¼“ï¼’ã€€ä½ã€€é™¢å£«ã€€ï¼ˆã€€ï¼¦ï½…ï½Œï½Œï½ï½—ã€€åŠã€€ï¼¦ï½ï½•ï½Žï½„ï½‰ï½Žï½‡ã€€ï¼¦ï½…ï½Œï½Œï½ï½—ã€€ï¼‰ã€€ï¼Œï¼–ï¼–ã€€ä½ã€€å”é™¢å£«ã€€ï¼ˆã€€ï¼¡ï½“ï½“ï½ï½ƒï½‰ï½ï½”ï½…ã€€ï¼¦ï½…ï½Œï½Œï½ï½—ã€€ï¼‰ã€€ï¼’ï¼”ã€€ä½ã€€é€šä¿¡ã€€é™¢å£«ã€€ï¼ˆã€€ï¼£ï½ï½’ï½’ï½…ï½“ï½ï½ï½Žï½„ï½‰ï½Žï½‡ã€€ï¼¦ï½…ï½Œï½Œï½ï½—ã€€ï¼‰ã€€åŠã€€ï¼’ã€€ä½ã€€é€šä¿¡ã€€å”é™¢å£«ã€€ï¼ˆã€€ï¼£ï½ï½’ï½’ï½…ï½“ï½ï½ï½Žï½„ï½‰ï½Žï½‡ã€€ï¼¡ï½“ï½“ï½ï½ƒï½‰ï½ï½”ï½…ã€€ï¼¦ï½…ï½Œï½Œï½ï½—ã€€ï¼‰ã€€çµ„æˆã€€ï¼ˆã€€ä¸ã€€åŒ…æ‹¬ã€€ä¸€ä¹ä¹å››å¹´ã€€ç•¶é¸ã€€è€…ã€€ï¼‰ã€€ï¼Œ

## BertCWSDemo.py needs files
>   src/BERT/*
>   in src: config.py, customize_modeling.py, preprocess.py, tokenization.py, TorchCRF.py, utilis.py
>
> text = '''
>        æ¬¾æ¬¾å¥½çœ‹çš„ç¾Žç”²ï¼Œç®€ç›´èƒ½æžç–¯â€œé€‰æ‹©ç»¼åˆç—‡â€è¯¶ï¼ã€‚è¿™æ˜¯ä¸€ç»„è¶…çº§æ¸©æŸ”åˆå¸¦ç‚¹è®¾è®¡æ„Ÿçš„ç¾Žç”²ðŸ’…ã€‚
>        æ˜¥å¤©æ¥äº†ðŸŒºã€‚ç¾Žç”²ä¹Ÿä»Žæ·±è‰²ç³»è½¬å˜ä¸ºæ·¡æ·¡çš„æµ…è‰²ç³»äº†ðŸ’ã€‚ä»Šå¤©ç»™å¤§å®¶æŽ¨èæœ€é€‚åˆæ˜¥å¤©çš„ç¾Žç”²ðŸ’…ã€‚
>        å¸Œæœ›ä½ ä»¬ä¼šå–œæ¬¢~ðŸ˜@MTå°ç¾Žé…± @MTæƒ…æŠ¥å±€ @ç¾Žå›¾ç§€ç§€ #æ˜¥å­£ç¾Žç”²##æ˜¾ç™½ç¾Žç”²##æ¸…æ–°ç¾Žç”²##insç¾Žç”²#
>      '''
> outputT = model.cutlist_noUNK([text])
> output = [' '.join(lst) for lst in outputT]
> o = ''
> for x in output: o += x + '\t'
> print(o+'\n')
> o = '''
>   æ¬¾æ¬¾ å¥½çœ‹ çš„ ç¾Žç”² ï¼Œ ç®€ç›´ èƒ½ æžç–¯ â€œ é€‰æ‹© ç»¼åˆç—‡ â€ è¯¶ ï¼ ã€‚ è¿™ æ˜¯ ä¸€ ç»„ è¶…çº§ æ¸©æŸ” åˆ å¸¦ ç‚¹ è®¾è®¡æ„Ÿ çš„
>   ç¾Žç”² ðŸ’… ã€‚ æ˜¥å¤© æ¥ äº† ðŸŒº ã€‚ ç¾Žç”² ä¹Ÿ ä»Ž æ·± è‰²ç³» è½¬å˜ ä¸º æ·¡æ·¡ çš„ æµ… è‰²ç³» äº† ðŸ’ ã€‚ ä»Šå¤© ç»™ å¤§å®¶ æŽ¨è
>   æœ€ é€‚åˆ æ˜¥å¤© çš„ ç¾Žç”² ðŸ’… ã€‚ å¸Œæœ› ä½ ä»¬ ä¼š å–œæ¬¢ ~ ðŸ˜ @ MT å°ç¾Žé…± @ MT æƒ…æŠ¥å±€ @ ç¾Žå›¾ ç§€ç§€ # æ˜¥å­£ ç¾Žç”² # # æ˜¾ç™½ ç¾Žç”² # # æ¸…æ–° ç¾Žç”² # # ins ç¾Žç”² #
> '''

