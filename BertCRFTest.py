#!/anaconda3/envs/haiqin370/bin/ python3
# -*- coding: utf-8 -*-
"""
Created on at 09:28 2019-02-21 
@author: haiqinyang

Feature: 

Scenario: 
"""
import os

from src.pkuseg.metrics import getFscoreFromBIOTagList
from tqdm import tqdm
from src.utilis import get_Ontonotes, convertList2BIOwithComma, BMES2BIO, space2Comma, load_4CWS
import pandas as pd
from src.config import args
from src.preprocess import CWS_BMEO # dataset_to_dataloader, randomly_mask_input, OntoNotesDataset
import time

import numpy as np
import torch
import pdb
import re

from src.BERT.modeling import BertConfig
from src.customize_modeling import BertCRFCWS
from src.utilis import save_model

import logging
logging.basicConfig(format = '%(asctime)s - %(levelname)s - %(name)s -   %(message)s',
                    datefmt = '%m/%d/%Y %H:%M:%S',
                    level = logging.INFO)
logger = logging.getLogger(__name__)

CONFIG_NAME = 'bert_config.json'
WEIGHTS_NAME = 'pytorch_model.bin'


def load_eval_model(label_list, args):
    if args.visible_device is not None:
        if isinstance(args.visible_device, int):
            args.visible_device = str(args.visible_device)
        elif isinstance(args.visible_device, (tuple, list)):
            args.visible_device = ','.join([str(_) for _ in args.visible_device])
        os.environ["CUDA_VISIBLE_DEVICES"] = args.visible_device

    if args.local_rank == -1 or args.no_cuda:
        device = torch.device("cuda" if torch.cuda.is_available() and not args.no_cuda else "cpu")
        n_gpu = torch.cuda.device_count()
    else:
        device = torch.device("cuda", args.local_rank)
        n_gpu = 1
        # Initializes the distributed backend which will take care of sychronizing nodes/GPUs
        torch.distributed.init_process_group(backend='nccl')
        if args.fp16:
            logger.info("16-bits training currently not supported in distributed training")
            args.fp16 = False # (see https://github.com/pytorch/pytorch/pull/13496)
    logger.info("device %s n_gpu %d distributed training %r", device, n_gpu, bool(args.local_rank != -1))

    if n_gpu > 0:
        torch.cuda.manual_seed_all(args.seed)

    if args.bert_model_dir is not None:
        config_file = os.path.join(args.bert_model_dir, CONFIG_NAME)
        bert_config = BertConfig.from_json_file(config_file)
    else:
        bert_config = BertConfig.from_json_file(args.bert_config_file)

    if args.num_hidden_layers>0 and args.num_hidden_layers<bert_config.num_hidden_layers:
        bert_config.num_hidden_layers = args.num_hidden_layers

    if args.max_seq_length > bert_config.max_position_embeddings:
        raise ValueError(
            "Cannot use sequence length {} because the BERT model was only trained up to sequence length {}".format(
            args.max_seq_length, bert_config.max_position_embeddings))

    if os.path.exists(args.output_dir) and os.listdir(args.output_dir):
        if not args.override_output:
            raise ValueError("Output directory ({}) already exists and is not empty.".format(args.output_dir))
        else:
            os.system("rm %s" % os.path.join(args.output_dir, '*'))

    model = BertCRFCWS(device, bert_config, args.vocab_file, args.max_seq_length, len(label_list), args.train_batch_size)

    if args.init_checkpoint is None:
        raise RuntimeError('Evaluating a random initialized model is not supported...!')
    #elif os.path.isdir(args.init_checkpoint):
    #    raise ValueError("init_checkpoint is not a file")
    else:
        weights_path = os.path.join(args.init_checkpoint, WEIGHTS_NAME)

        # main code copy from modeling.py line after 506
        state_dict = torch.load(weights_path)

        missing_keys = []
        unexpected_keys = []
        error_msgs = []
        # copy state_dict so _load_from_state_dict can modify it
        metadata = getattr(state_dict, '_metadata', None)
        state_dict = state_dict.copy()
        if metadata is not None:
            state_dict._metadata = metadata

        def load(module, prefix=''):
            local_metadata = {} if metadata is None else metadata.get(prefix[:-1], {})
            module._load_from_state_dict(
                state_dict, prefix, local_metadata, True, missing_keys, unexpected_keys, error_msgs)
            for name, child in module._modules.items():
                if child is not None:
                    load(child, prefix + name + '.')
        load(model, prefix='' if hasattr(model, 'bert') else 'bert.')
        if len(missing_keys) > 0:
            logger.info("Weights of {} not initialized from pretrained model: {}".format(
                model.__class__.__name__, missing_keys))
        if len(unexpected_keys) > 0:
            logger.info("Weights from pretrained model not used in {}: {}".format(
                model.__class__.__name__, unexpected_keys))

    model.to(device)
    if args.local_rank != -1:
        model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[args.local_rank],
                                                          output_device=args.local_rank)
    elif n_gpu > 1 and not args.no_cuda:
        model = torch.nn.DataParallel(model)

    if args.bert_model is not None:
        weights = torch.load(args.bert_model, map_location='cpu')

        try:
            model.load_state_dict(weights)
        except RuntimeError:
            model.module.load_state_dict(weights)

    return model, device


def do_eval_with_model(model, data_dir, type, output_dir, mode=False):
    df = get_Ontonotes(data_dir, type)

    bertCRFList = []
    trueLabelList = []

    output_diff_file = os.path.join(output_dir, type+"_diff.txt")

    for i, data in tqdm(enumerate(df.itertuples())):
        sentence = data.text
        #sentence = re.sub('â€œ|â€', '"', sentence)
        #rs_full = jieba.lcut(sentence, cut_all=True) # Full mode, all possible cuts
        #rs_ser = jieba.lcut_for_search(sentence) # search engine mode, similar to Full mode

        # sentence = 'å°æ¹¾çš„å…¬è§†ä»Šå¤©ä¸»åŠçš„å°åŒ—å¸‚é•¿å€™é€‰äººè¾©è®ºä¼šï¼Œ'
        # rs_precision = jieba.lcut(sentence, cut_all=False)
        #   rs_precision = ['å°æ¹¾', 'çš„', 'å…¬è§†', 'ä»Šå¤©', 'ä¸»åŠ', 'çš„', 'å°åŒ—', 'å¸‚é•¿', 'å€™é€‰äºº', 'è¾©è®ºä¼š', 'ï¼Œ']
        # jieba_rs = ' '.join(rs_precision)
        #   jieba_rs = 'å°æ¹¾ çš„ å…¬è§† ä»Šå¤© ä¸»åŠ çš„ å°åŒ— å¸‚é•¿ å€™é€‰äºº è¾©è®ºä¼š ï¼Œ'

        #rs_precision = model.cut(sentence, mode)
        rs_precision = model.cutlist(sentence)
        bertCRF_rs = ' '.join(rs_precision)

        #str_precision = convertList2BMES(rs_precision)
        str_BIO = convertList2BIOwithComma(rs_precision, model.tokenizer)
        bertCRFList.append(str_BIO)

        tl = BMES2BIO(data.label)
        tl = space2Comma(tl)
        trueLabelList.append(tl)

        if str_BIO != tl:
            print('{:d}: '.format(i))
            print(sentence)
            print(data.text_seg)
            print(bertCRF_rs)
            print(tl)
            print(str_BIO)
            print('\n')

        with open(output_diff_file, "a+") as writer:
            writer.write('{:d}: '.format(i))
            writer.write(sentence+'\n')
            writer.write(data.text_seg+'\n')
            writer.write(bertCRF_rs+'\n')
            writer.write(tl+'\n')
            writer.write(str_BIO+'\n\n')

    score, scoreInfo = getFscoreFromBIOTagList(trueLabelList, bertCRFList)

    print('Eval ' + type + ' results:')
    print('Test F1, Precision, Recall, Acc, No. Tags: {:.3f}, {:.3f}, {:.3f}, {:.3f}, {:d}'.format(score[0], \
                                                  score[1], score[2], score[3], scoreInfo[-1]))

    output_eval_file = os.path.join(output_dir, "eval_results.txt")
    with open(output_eval_file, "a+") as writer:
        writer.write('Eval ' + type + ' results: ')
        writer.write("F1: {:.3f}, P: {:.3f}, R: {:.3f}, Acc: {:.3f}, No. Tags: {:d}\n\n".format(score[0], \
                                                score[1], score[2], score[3], scoreInfo[-1]))

    return score, scoreInfo


def do_eval_df_with_model(model, df, output_diff_file, output_eval_file, type):
    bertCRFList = []
    trueLabelList = []

    sent_list = []
    truelabelstr = ''


    for i, data in tqdm(enumerate(df.itertuples())):
        sentence = data.text
        #sentence = re.sub('â€œ|â€', '"', sentence)

        sent_list.append(sentence)

        tl = BMES2BIO(data.label)
        tl = space2Comma(tl)
        trueLabelList.append(tl)
        truelabelstr += tl

    rs_precision_all = model.cutlist_noUNK(sent_list)

    for idx in tqdm(range(len(rs_precision_all))):
        rs_precision = rs_precision_all[idx]
        bertCRF_rs = ' '.join(rs_precision)

        str_BIO = convertList2BIOwithComma(rs_precision)
        bertCRFList.append(str_BIO)

        tl = trueLabelList[idx]

        sentence = df.text[idx]
        text_seg = df.text_seg[idx]
        if str_BIO != tl:
            print('{:d}: '.format(idx))
            print(sentence)
            print(text_seg)
            print(bertCRF_rs)
            print(tl)
            print(str_BIO)
            print('\n')

        with open(output_diff_file, "a+") as writer:
            writer.write('{:d}: '.format(i))
            writer.write(sentence+'\n')
            writer.write(text_seg+'\n')
            writer.write(bertCRF_rs+'\n')
            writer.write(tl+'\n')
            writer.write(str_BIO+'\n\n')

    #score, scoreInfo = getFscoreFromBIOTagList([truelabelstr], [str_BIO])
    score, scoreInfo = getFscoreFromBIOTagList(trueLabelList, bertCRFList)

    print('Eval ' + type + ' results:')
    print('Test F1, Precision, Recall, Acc, No. Tags: {:.3f}, {:.3f}, {:.3f}, {:.3f}, {:d}'.format(score[0], \
                                                  score[1], score[2], score[3], scoreInfo[-1]))

    with open(output_eval_file, "a+") as writer:
        writer.write('Eval ' + type + ' results: ')
        writer.write("F1: {:.3f}, P: {:.3f}, R: {:.3f}, Acc: {:.3f}, No. Tags: {:d}\n\n".format(score[0], \
                                                score[1], score[2], score[3], scoreInfo[-1]))

    return score, scoreInfo


def do_eval_with_file_model(model, infile, output_dir, otag, tagMode, mode=False):
    # model: BertCRF model
    # infile: input file in tsv format
    # output_dir: the directory to store evaluation file
    # otag: to denote what type of file should be stored
    # tagMode: to indicate the label coding is 'BIO' or 'BMES'

    df = pd.read_csv(infile, sep='\t')

    bertCRFList = []
    trueLabelList = []

    output_diff_file = os.path.join(output_dir, otag+"_diff.txt")

    with open(output_diff_file, "a+") as writer:
        writer.write('order: source, true, prediction\n')

    for i, data in tqdm(enumerate(df.itertuples())):
        sentence = data.text
        #rs_full = jieba.lcut(sentence, cut_all=True) # Full mode, all possible cuts
        #rs_ser = jieba.lcut_for_search(sentence) # search engine mode, similar to Full mode

        # sentence = 'å°æ¹¾çš„å…¬è§†ä»Šå¤©ä¸»åŠçš„å°åŒ—å¸‚é•¿å€™é€‰äººè¾©è®ºä¼šï¼Œ'
        # rs_precision = jieba.lcut(sentence, cut_all=False)
        #   rs_precision = ['å°æ¹¾', 'çš„', 'å…¬è§†', 'ä»Šå¤©', 'ä¸»åŠ', 'çš„', 'å°åŒ—', 'å¸‚é•¿', 'å€™é€‰äºº', 'è¾©è®ºä¼š', 'ï¼Œ']
        # jieba_rs = ' '.join(rs_precision)
        #   jieba_rs = 'å°æ¹¾ çš„ å…¬è§† ä»Šå¤© ä¸»åŠ çš„ å°åŒ— å¸‚é•¿ å€™é€‰äºº è¾©è®ºä¼š ï¼Œ'
        if tagMode=='BIO':
            tl = data.src_seg
        elif tagMode=='BMES':
            tl = BMES2BIO(data.src_seg)
            tl = space2Comma(tl)

        rs_precision = model.cutlist(sentence)
        bertCRF_rs = ' '.join(rs_precision)

        #str_precision = convertList2BMES(rs_precision)
        str_BIO = convertList2BIOwithComma(rs_precision, model.tokenizer)

        bertCRFList.append(str_BIO)
        trueLabelList.append(tl)

        if str_BIO != tl:
            print('{:d}: '.format(i))
            print(sentence)
            print(data.text_seg)
            print(bertCRF_rs)
            print(tl)
            print(str_BIO)
            print('\n')

        with open(output_diff_file, "a+") as writer:
            writer.write('{:d}: '.format(i))
            writer.write(sentence+'\n')
            writer.write(data.text_seg+'\n')
            writer.write(bertCRF_rs+'\n')
            writer.write(tl+'\n')
            writer.write(str_BIO+'\n\n')

    score, sInfo = getFscoreFromBIOTagList(trueLabelList, bertCRFList)

    print('Eval ' + otag + ' results:')
    print("F1: {:.3f}, P: {:.3f}, R: {:.3f}, Acc: {:.3f}, Token: {:d}\n\n".format(score[0], \
                                              score[1], score[2], score[3], sInfo[-1]))

    output_eval_file = os.path.join(output_dir, "eval_results.txt")
    with open(output_eval_file, "a+") as writer:
        writer.write('Eval ' + otag + ' results: ')
        writer.write("F1: {:.3f}, P: {:.3f}, R: {:.3f}, Acc: {:.3f}, Token: {:d}\n\n".format(score[0], \
                                             score[1], score[2], score[3], sInfo[-1]))

    return score

def do_eval_list_with_file_model(model, infile, output_dir, otag, tagMode, mode=False):
    # model: BertCRF model
    # infile: input file in tsv format
    # output_dir: the directory to store evaluation file
    # otag: to denote what type of file should be stored
    # tagMode: to indicate the label coding is 'BIO' or 'BMES'

    df = pd.read_csv(infile, sep='\t')

    bertCRFList = []
    trueLabelList = []

    output_diff_file = os.path.join(output_dir, otag+"_diff.txt")

    with open(output_diff_file, "a+") as writer:
        writer.write('order: source, true, prediction\n')

    for i, data in tqdm(enumerate(df.itertuples())):
        sentence = data.text
        #rs_full = jieba.lcut(sentence, cut_all=True) # Full mode, all possible cuts
        #rs_ser = jieba.lcut_for_search(sentence) # search engine mode, similar to Full mode

        # sentence = 'å°æ¹¾çš„å…¬è§†ä»Šå¤©ä¸»åŠçš„å°åŒ—å¸‚é•¿å€™é€‰äººè¾©è®ºä¼šï¼Œ'
        # rs_precision = jieba.lcut(sentence, cut_all=False)
        #   rs_precision = ['å°æ¹¾', 'çš„', 'å…¬è§†', 'ä»Šå¤©', 'ä¸»åŠ', 'çš„', 'å°åŒ—', 'å¸‚é•¿', 'å€™é€‰äºº', 'è¾©è®ºä¼š', 'ï¼Œ']
        # jieba_rs = ' '.join(rs_precision)
        #   jieba_rs = 'å°æ¹¾ çš„ å…¬è§† ä»Šå¤© ä¸»åŠ çš„ å°åŒ— å¸‚é•¿ å€™é€‰äºº è¾©è®ºä¼š ï¼Œ'
        if tagMode=='BIO':
            tl = data.src_seg
        elif tagMode=='BMES':
            tl = BMES2BIO(data.src_seg)
            tl = space2Comma(tl)

        rs_precision = model.cutlist(sentence)
        bertCRF_rs = ' '.join(rs_precision)

        #str_precision = convertList2BMES(rs_precision)
        str_BIO = convertList2BIOwithComma(rs_precision, model.tokenizer)

        bertCRFList.append(str_BIO)
        trueLabelList.append(tl)

        if str_BIO != tl:
            print('{:d}: '.format(i))
            print(sentence)
            print(data.text_seg)
            print(bertCRF_rs)
            print(tl)
            print(str_BIO)
            print('\n')

        with open(output_diff_file, "a+") as writer:
            writer.write('{:d}: '.format(i))
            writer.write(sentence+'\n')
            writer.write(data.text_seg+'\n')
            writer.write(bertCRF_rs+'\n')
            writer.write(tl+'\n')
            writer.write(str_BIO+'\n\n')

    score, sInfo = getFscoreFromBIOTagList(trueLabelList, bertCRFList)

    print('Eval ' + otag + ' results:')
    print("F1: {:.3f}, P: {:.3f}, R: {:.3f}, Acc: {:.3f}, Token: {:d}\n\n".format(score[0], \
                                              score[1], score[2], score[3], sInfo[-1]))

    output_eval_file = os.path.join(output_dir, "eval_results.txt")
    with open(output_eval_file, "a+") as writer:
        writer.write('Eval ' + otag + ' results: ')
        writer.write("F1: {:.3f}, P: {:.3f}, R: {:.3f}, Acc: {:.3f}, Token: {:d}\n\n".format(score[0], \
                                             score[1], score[2], score[3], sInfo[-1]))

    return score

def load_model(label_list, args):
    if args.visible_device is not None:
        if isinstance(args.visible_device, int):
            args.visible_device = str(args.visible_device)
        elif isinstance(args.visible_device, (tuple, list)):
            args.visible_device = ','.join([str(_) for _ in args.visible_device])
        os.environ["CUDA_VISIBLE_DEVICES"] = args.visible_device

    if args.local_rank == -1 or args.no_cuda:
        device = torch.device("cuda" if torch.cuda.is_available() and not args.no_cuda else "cpu")
        n_gpu = torch.cuda.device_count()
    else:
        device = torch.device("cuda", args.local_rank)
        n_gpu = 1
        # Initializes the distributed backend which will take care of sychronizing nodes/GPUs
        torch.distributed.init_process_group(backend='nccl')
        if args.fp16:
            logger.info("16-bits training currently not supported in distributed training")
            args.fp16 = False # (see https://github.com/pytorch/pytorch/pull/13496)
    logger.info("device %s n_gpu %d distributed training %r", device, n_gpu, bool(args.local_rank != -1))

    if n_gpu > 0:
        torch.cuda.manual_seed_all(args.seed)

    if args.bert_model_dir is not None:
        config_file = os.path.join(args.bert_model_dir, CONFIG_NAME)
        bert_config = BertConfig.from_json_file(config_file)
    else:
        bert_config = BertConfig.from_json_file(args.bert_config_file)

    if args.num_hidden_layers>0 and args.num_hidden_layers<bert_config.num_hidden_layers:
        bert_config.num_hidden_layers = args.num_hidden_layers

    if args.max_seq_length > bert_config.max_position_embeddings:
        raise ValueError(
            "Cannot use sequence length {} because the BERT model was only trained up to sequence length {}".format(
            args.max_seq_length, bert_config.max_position_embeddings))

    if os.path.exists(args.output_dir) and os.listdir(args.output_dir):
        if not args.override_output:
            raise ValueError("Output directory ({}) already exists and is not empty.".format(args.output_dir))
        else:
            os.system("rm %s" % os.path.join(args.output_dir, '*'))

    model = BertCRFCWS(device, bert_config, args.vocab_file, args.max_seq_length, len(label_list))

    if args.init_checkpoint is None:
        raise RuntimeError('Evaluating a random initialized model is not supported...!')
    #elif os.path.isdir(args.init_checkpoint):
    #    raise ValueError("init_checkpoint is not a file")
    else:
        weights_path = os.path.join(args.init_checkpoint, WEIGHTS_NAME)

        # main code copy from modeling.py line after 506
        state_dict = torch.load(weights_path)

        missing_keys = []
        unexpected_keys = []
        error_msgs = []
        # copy state_dict so _load_from_state_dict can modify it
        metadata = getattr(state_dict, '_metadata', None)
        state_dict = state_dict.copy()
        if metadata is not None:
            state_dict._metadata = metadata

        def load(module, prefix=''):
            local_metadata = {} if metadata is None else metadata.get(prefix[:-1], {})
            module._load_from_state_dict(
                state_dict, prefix, local_metadata, True, missing_keys, unexpected_keys, error_msgs)
            for name, child in module._modules.items():
                if child is not None:
                    load(child, prefix + name + '.')
        load(model, prefix='' if hasattr(model, 'bert') else 'bert.')
        if len(missing_keys) > 0:
            logger.info("Weights of {} not initialized from pretrained model: {}".format(
                model.__class__.__name__, missing_keys))
        if len(unexpected_keys) > 0:
            logger.info("Weights from pretrained model not used in {}: {}".format(
                model.__class__.__name__, unexpected_keys))

    model.to(device)
    if args.local_rank != -1:
        model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[args.local_rank],
                                                          output_device=args.local_rank)
    elif n_gpu > 1 and not args.no_cuda:
        model = torch.nn.DataParallel(model)

    return model, device

def preload(args):
    processors = {
        "ontonotes_cws": lambda: CWS_BMEO(nopunc=args.nopunc),
    }

    task_name = args.task_name.lower()
    if task_name not in processors:
        raise ValueError("Task not found: %s" % (task_name))

    # Prepare model
    processor = processors[task_name]()

    label_list = processor.get_labels()
    model, device = load_model(label_list, args)

    if args.bert_model is not None:
        if torch.cuda.is_available():
            weights = torch.load(args.bert_model)
        else:
            weights = torch.load(args.bert_model, map_location='cpu')

        try:
            model.load_state_dict(weights)
        except RuntimeError:
            model.module.load_state_dict(weights)

    model.to(device)
    model.eval()
    save_model(model, args.output_dir + 'model_eval.tsv')

    return model


def eval_ontonotes(args):
    #data_dir = '/Users/haiqinyang/Downloads/datasets/ontonotes-release-5.0/ontonote_data/proc_data/final_data'

    #output_dir='./tmp/ontonotes/BerTCRF/'
    localtime = time.localtime(time.time())
    data_dir = args.data_dir
    output_dir = args.output_dir + 'nhl' + str(args.num_hidden_layers) + '_' + str(localtime.tm_year) \
                 + '_' + str(localtime.tm_mon) + '_' + str(localtime.tm_mday) \
                 + '_' + str(localtime.tm_hour) + str(localtime.tm_min) + str(localtime.tm_sec)
    os.makedirs(output_dir, exist_ok=True)

    model = preload(args)

    text1 = '''
        ç›®å‰ç”±ï¼’ï¼“ï¼’ä½é™¢å£«ï¼ˆï¼¦ï½…ï½Œï½Œï½ï½—åŠï¼¦ï½ï½•ï½ï½„ï½‰ï½ï½‡ã€€ï¼¦ï½…ï½Œï½Œï½ï½—ï¼‰ï¼Œï¼–ï¼–ä½å”é™¢å£«ï¼ˆï¼¡ï½“ï½“ï½ï½ƒï½‰ï½ï½”ï½…ã€€ï¼¦ï½…ï½Œï½Œï½ï½—ï¼‰
        ï¼’ï¼”ä½é€šä¿¡é™¢å£«ï¼ˆï¼£ï½ï½’ï½’ï½…ï½“ï½ï½ï½ï½„ï½‰ï½ï½‡ã€€ï¼¦ï½…ï½Œï½Œï½ï½—ï¼‰åŠï¼’ä½é€šä¿¡å”é™¢å£«
        ï¼ˆï¼£ï½ï½’ï½’ï½…ï½“ï½ï½ï½ï½„ï½‰ï½ï½‡ã€€ï¼¡ï½“ï½“ï½ï½ƒï½‰ï½ï½”ï½…ã€€ï¼¦ï½…ï½Œï½Œï½ï½—ï¼‰çµ„æˆï¼ˆä¸åŒ…æ‹¬ä¸€ä¹ä¹å››å¹´ç•¶é¸è€…ï¼‰
        # of students is 256.
    '''
    outputT1 = model.cut2(text1)
    print(text1)
    print(' '.join(outputT1)+'\n')

    text2 = 'æ¬¾æ¬¾å¥½çœ‹çš„ç¾ç”²ï¼Œç®€ç›´èƒ½æç–¯â€œé€‰æ‹©ç»¼åˆç—‡â€è¯¶ï¼ã€‚è¿™æ˜¯ä¸€ç»„è¶…çº§æ¸©æŸ”åˆå¸¦ç‚¹è®¾è®¡æ„Ÿçš„ç¾ç”²ğŸ’…ã€‚æ˜¥å¤©æ¥äº†ğŸŒºã€‚ç¾ç”²ä¹Ÿä»æ·±è‰²ç³»è½¬å˜ä¸ºæ·¡æ·¡çš„æµ…è‰²ç³»äº†ğŸ’ã€‚ä»Šå¤©ç»™å¤§å®¶æ¨èæœ€é€‚åˆæ˜¥å¤©çš„ç¾ç”²ğŸ’…ã€‚å¸Œæœ›ä½ ä»¬ä¼šå–œæ¬¢~ğŸ˜@MTå°ç¾é…± @MTæƒ…æŠ¥å±€ @ç¾å›¾ç§€ç§€ #æ˜¥å­£ç¾ç”²##æ˜¾ç™½ç¾ç”²##æ¸…æ–°ç¾ç”²##insç¾ç”²#'
    outputT2 = model.cut2(text2)
    print(text2)
    print(' '.join(outputT2)+'\n')


    text3 = '''
    åœ¨æœé‡å„ç•Œä¸ºæ ¸å››äº‹ä»¶åµåš·ä¸ä¼‘ä¹‹é™…ï¼Œå‘ç”Ÿåœ¨ä¸€æœˆä¸­æ—¬çš„å¦ä¸é¾™å‘ç”Ÿæ€æ²¹æ±¡äº‹ä»¶ï¼Œç›´åˆ°äºŒæœˆåº•æ‰å—åˆ°åˆæ­¥æ§åˆ¶ï¼ŒåŠ ä¸Šè¿‘æ¥å°æ¹¾å±±åŒºæ£®æ—ç«ç¾å±¡æ‰‘å±¡èµ·ï¼Œæ˜¾ç°å°æ¹¾ç”Ÿæ€çš„å±æœºï¼Œå·²ä¸å®¹äººä»¬å°†ç„¦ç‚¹æ”¾åœ¨å•ä¸€çš„å¼€å‘äº‹ä»¶ä¸Šï¼Œå…¨é¢æ€§çš„å¤§åœ°ç ´åä¸è‡ªç„¶åæ‰‘æ›´å€¼å¾—å…³æ³¨ã€‚
    '''
    outputT3 = model.cutlist([text3])
    output3 = [' '.join(lst) for lst in outputT3]
    print(text3)
    print(output3[0]+'\n')

    text4 = '''
      åˆ›ç»´åˆä¸€æ³¢é»‘ç§‘æŠ€ã€‚  å°¸ä½“å¡é€šé£ç®¡ã€‚  è¿™æ¬¡æ’ä¸Šæµ·åº•äº†ã€‚  æ¬¢è¿æ–°è€å¸ˆç”Ÿå‰æ¥å°±é¤ã€‚  å·¥ä¿¡å¤„å¥³å¹²äº‹æ¯æœˆç»è¿‡ä¸‹å±ç§‘å®¤éƒ½äº²å£äº¤ä»£24å£äº¤æ¢æœºç­‰æŠ€æœ¯æ€§å™¨ä»¶çš„å®‰è£…å·¥ç¨‹ã€‚  
      ç»“å©šå’Œå°šæœªç»“å©šçš„çš„ç¡®åœ¨å¹²æ‰°åˆ†è¯å“ˆã€‚  å•†å“å’ŒæœåŠ¡ã€‚  ä¹°æ°´æœç„¶åæ¥ä¸–åšä¼šæœ€åå»ä¸–åšä¼šã€‚  ä¸­å›½çš„é¦–éƒ½æ˜¯åŒ—äº¬ã€‚  
      éšç€é¡µæ¸¸å…´èµ·åˆ°ç°åœ¨é¡µæ¸¸ç¹ç››ï¼Œä¾èµ–äºå­˜æ¡£è¿›è¡Œé€»è¾‘åˆ¤æ–­çš„è®¾è®¡å‡å°‘äº†ï¼Œä½†è¿™å—éƒ½ä¸èƒ½å®Œå…¨å¿½ç•¥æ‰ã€‚  
    '''
    outputT4 = model.cutlist([text1, text2, text3, text4])
    output4 = [' '.join(lst) for lst in outputT4]
    print(text1+'\t'+text2+'\t'+text3+'\t'+text4)
    o4 = ''
    for x in output4: o4 += x + '\t'
    print(o4+'\n')

    t5 = '''
        å•æªåŒ¹é©¬é€›è‹±å›½â€”â€”ä¼¦æ•¦ç¯‡ã€‚ä¼¦æ•¦å°±æ˜¯è¿™ä¸ªæ ·å­åˆæ¬¡æ¥åˆ°è¿™ä¸ªâ€œè€ç‰Œèµ„æœ¬ä¸»ä¹‰â€çš„â€œé›¾éƒ½â€œï¼Œ
        å°±åƒå›åˆ°äº†ä¸Šæµ·ï¼Œä¸€å¹¢å¹¢ä¸é«˜çš„å°æ¥¼ï¼Œæ˜¾å¾—å¼‚å¸¸é™ˆæ—§ï¼Œå¾ˆå¤šæ¥¼æˆ¿è¢«æ•°ç™¾å¹´çƒŸå°˜ç†çš„å°±åƒè¢«åˆ·äº†ä¸€å±‚é»‘è‰²çš„æ²¹æ¼†ï¼Œ
        æ²¹å…‰é”ƒäº®ï¼Œå¦‚æœä¸æ˜¯æ—è¾¹çš„æ¥¼æˆ¿æ­£åœ¨æ¸…æ´—ï¼Œå¾ˆéš¾è®©äººç›¸ä¿¡å¦‚ä»Šçš„ä¼¦æ•¦æ˜¯é¥±ç»æ±¡æŸ“æ²§æ¡‘ååŠæ—¶åˆ¹è½¦çš„é«˜æ‰‹ï¼Œ
        å› ä¸ºä¸€åº§ç°ä»£åŒ–çš„å›½é™…å¤§éƒ½å¸‚ä¹Ÿæ˜¯æœ‰ä¸å°‘æ¥¼æˆ¿æ˜¯é»‘è‰²çš„å‘¢ï¼Œé»‘è‰²æ˜¾å¾—å‡é‡ã€é«˜é›…ï¼Œä½†æ˜¯ç»å¯¹ä¸èƒ½é æ²¹çƒŸå»ç†â€¦â€¦å µè½¦ï¼Œ
        æ˜¯æ‰€æœ‰å¤§éƒ½å¸‚çš„é€šç—…ï¼Œè™½ç„¶ä¸è¶³ä¸ºæ€ªï¼Œä½†æ˜¯ï¼Œ1988å¹´çš„åŒ—äº¬è¿˜æ²¡æœ‰é‚£ä¹ˆå¤šçš„è½¦ï¼Œä¹Ÿæ²¡æœ‰å…¨åŸå¤§å µè½¦çš„ç°è±¡ï¼Œ
        æœ‰çš„æ˜¯åˆšåˆšå¼€å§‹çš„â€œé æ²¹çƒŸå’Œæ±½è½¦çš„å°¾æ°”çƒŸç†ç«ç‡ç¾ä¸½çš„å¤åŸâ€ï¼Œæœ‰è°èƒ½å¤Ÿæƒ³åˆ°ï¼ŒçŸ­çŸ­çš„åå¹´ï¼ŒåŒ—äº¬å°±æ°”å–˜ååçš„è¿½èµ¶ä¸Šäº†ä¼¦æ•¦ï¼Œ
        æ²¡æœ‰ä¸€æ¡æ´å‡€çš„æ²³æµï¼Œæ²¡æœ‰æ¸…æ–°çš„ç©ºæ°”ï¼Œæœ‰çš„æ˜¯è®©äººçª’æ¯çš„ç©ºæ°”æ±¡æŸ“â€¦â€¦.ä»¥åŠï¼Œè®©äººå§‹æ–™æœªåŠçš„å…¨åŸå¤§å µè½¦ã€‚
        å¦‚æœï¼Œæˆ‘ä»¬é‚£äº›è´Ÿè´£åŸå¸‚å»ºè®¾è§„åˆ’çš„å…ˆç”Ÿä»¬ï¼Œåœ¨å›½å¤–ï¼Œä¸åªåªæ˜¯æ¸¸å±±ç©æ°´çš„è¯ï¼Œå¸¦å›åˆ«äººçš„æ•™è®­ã€æ€»ç»“åˆ«äººçš„ç»éªŒçš„è¯ï¼Œ
        æˆ‘ä»¬è¿™ä¸ªè¢«ç©·ç¥–å…ˆæ¯çš„â€œä¸€å¡Œç³Šæ¶‚â€çš„è„†å¼±çš„ç”Ÿæ€ç¯å¢ƒä¹Ÿä¸ä¼šå†ç»å—20ä¸–çºª90å¹´ä»£çš„ç°ä»£åŒ–çš„å¤§æ±¡æŸ“äº†ã€‚ä½†æ˜¯ï¼Œ
        ä¼¦æ•¦æ˜¯ä¸€åº§æ”¹è¿‡è‡ªæ–°çš„åŸå¸‚ï¼Œäººå®¶ç—›å®šæ€ç—›ï¼Œç´§æ€¥åˆ¹è½¦ï¼ŒåŠæ—¶çš„æ²»ç†äº†æ±¡æŸ“ï¼Œæˆ‘ä»¬åœ¨æ³°å¾å£«æ²³é‡Œå¯ä»¥çœ‹åˆ°é±¼å„¿åœ¨è‡ªç”±çš„ç¿»æ»šï¼Œ
        å¤©ç©ºæ¹›è“ï¼Œç¿ ç»¿çš„è‰åœ°ä¸å…°å¤©è¾‰æ˜ ç€ï¼Œä¸€ç‰‡â€œæ±¡æŸ“å¤§æˆ˜â€åçš„å’Œå¹³æ™¯è±¡    
    '''
    outputT5 = model.cutlist_noUNK([t5])
    output5 = [' '.join(lst) for lst in outputT5]
    print(t5)
    print(output5[0]+'\n')

    t6 = 'ä¸­å›½é˜Ÿä»¥ï¼‘ï¼‘ï¼šï¼‘æˆ˜èƒœä¼Šæœ—é˜Ÿã€‚ä¸­å›½é˜Ÿåœ¨å½“æ™šçš„å¦ä¸€åœºå¯¹é˜µå·´å‹’æ–¯å¦é˜Ÿçš„æ¯”èµ›ä¸­åŒæ ·è·èƒœï¼Œæ¯”åˆ†æ˜¯ï¼™ï¼™ï¼šï¼’ï¼ã€‚'
    outputT6 = model.cutlist_noUNK([t6])
    output6 = [' '.join(lst) for lst in outputT6]
    print(t6)
    print(output6[0]+'\n')

    output_eval_file = os.path.join(output_dir, "eval_results.txt")
    with open(output_eval_file, "a+") as writer:
        writer.write(args.bert_model + '\n')
        writer.write(str(args.num_hidden_layers) + '\n')

    mode = False
    #mode = True
    type = 'tmp_test'
    df = get_Ontonotes(data_dir, type)
    output_diff_file = os.path.join(output_dir, type+"_diff.txt")
    output_eval_file = os.path.join(output_dir, "eval_results.txt")
    do_eval_df_with_model(model, df, output_diff_file, output_eval_file, type)

    type = 'test'
    df = get_Ontonotes(data_dir, type)
    output_diff_file = os.path.join(output_dir, type+"_diff.txt")
    output_eval_file = os.path.join(output_dir, "eval_results.txt")

    do_eval_df_with_model(model, df, output_diff_file, output_eval_file, type)

    #do_eval_with_model(model, data_dir, type, output_dir, mode)

    type = 'dev'
    df = get_Ontonotes(data_dir, type)
    output_diff_file = os.path.join(output_dir, type+"_diff.txt")
    output_eval_file = os.path.join(output_dir, "eval_results.txt")
    do_eval_df_with_model(model, df, output_diff_file, output_eval_file, type)
    #do_eval_with_model(model, data_dir, type, output_dir, mode)

    type = 'train'
    df = get_Ontonotes(data_dir, type)
    output_diff_file = os.path.join(output_dir, type+"_diff.txt")
    output_eval_file = os.path.join(output_dir, "eval_results.txt")
    do_eval_df_with_model(model, df, output_diff_file, output_eval_file, type)
    #do_eval_with_model(model, data_dir, type, output_dir, mode)


def eval_CWS(args):
    fnames = ['as', 'cityu', 'msr', 'pku']
    modes = ['train', 'test']
    tagMode = 'BIO'
    #data_dir = '/Users/haiqinyang/Downloads/datasets/ontonotes-release-5.0/ontonote_data/proc_data/cws/'
    data_dir = args.data_dir + tagMode + '/'

    #output_dir='./tmp/cws/jieba/'
    output_dir = args.output_dir
    os.makedirs(output_dir, exist_ok=True)

    model = preload(args)

    for wt in fnames:
        for md in modes:
            infile = data_dir + wt + '_' + md + '.tsv'
            otag = wt + '_' + md

            df = load_4CWS(infile) #pd.read_csv(infile, sep='\t')        
            output_diff_file = os.path.join(output_dir, otag+"_diff.txt")
            output_eval_file = os.path.join(output_dir, "eval_results.txt")
            do_eval_df_with_model(model, df, output_diff_file, output_eval_file, otag)
            #do_eval_with_file_model(model, infile, output_dir, otag, tagMode)


def set_local_eval_ontonotes_param():
    return {'task_name': 'ontonotes_CWS',
            'model_type': 'sequencelabeling',
            'data_dir': '/Users/haiqinyang/Downloads/datasets/ontonotes-release-5.0/ontonote_data/proc_data/4ner_data/',
            'vocab_file': '/Users/haiqinyang/Downloads/codes/pytorch-pretrained-BERT-master/models/bert-base-chinese/vocab.txt',
            'bert_config_file': '/Users/haiqinyang/Downloads/codes/pytorch-pretrained-BERT-master/models/bert-base-chinese/bert_config.json',
            'output_dir': '/Users/haiqinyang/Downloads/datasets/ontonotes-release-5.0/ontonote_data/proc_data/eval/2019_3_23/rs/nhl3/',
            'do_lower_case': True,
            'train_batch_size': 128,
            'max_seq_length': 128,
            'num_hidden_layers': 3,
            'init_checkpoint': '/Users/haiqinyang/Downloads/codes/pytorch-pretrained-BERT-master/models/bert-base-chinese/',
            'bert_model': '/Users/haiqinyang/Downloads/datasets/ontonotes-release-5.0/ontonote_data/proc_data/eval/2019_3_23/models/nhl3/weights_epoch03.pt',
            'override_output': True,
            'tensorboardWriter': False
            }

def set_local_eval_4CWS_param():
    return {'task_name': 'ontonotes_CWS',
            'data_dir': '/Users/haiqinyang/Downloads/datasets/ontonotes-release-5.0/ontonote_data/proc_data/cws/',
            'vocab_file': '/Users/haiqinyang/Downloads/codes/pytorch-pretrained-BERT-master/models/bert-base-chinese/vocab.txt',
            'bert_config_file': '/Users/haiqinyang/Downloads/codes/pytorch-pretrained-BERT-master/models/bert-base-chinese/bert_config.json',
            'output_dir': '/Users/haiqinyang/Downloads/datasets/ontonotes-release-5.0/ontonote_data/proc_data/eval/ontonotes_2019_3_23_nhl3/',
            'do_lower_case': True,
            'train_batch_size': 128,
            'max_seq_length': 128,
            'num_hidden_layers': 3,
            'init_checkpoint': '/Users/haiqinyang/Downloads/codes/pytorch-pretrained-BERT-master/models/bert-base-chinese/',
            'bert_model': '/Users/haiqinyang/Downloads/datasets/ontonotes-release-5.0/ontonote_data/proc_data/eval/2019_3_23/models/nhl3/weights_epoch03.pt',
            'override_output': True,
            'tensorboardWriter': False
            #             'model_type': 'sequencelabeling',
            }

def set_server_eval_ontonotes_param():
    return {'task_name': 'ontonotes_CWS',
            'model_type': 'sequencelabeling',
            'data_dir': '../data/ontonotes5/4ner_data/',
            'vocab_file': '../models/bert-base-chinese/vocab.txt',
            'bert_config_file': '../models/bert-base-chinese/bert_config.json',
            'output_dir': './tmp_2019_3_22/out/ontonotes/',
            'do_lower_case': True,
            'train_batch_size': 128,
            'visible_device': 0,
            'max_seq_length': 128,
            'num_hidden_layers': 3,
            'init_checkpoint': '../models/bert-base-chinese/',
            'bert_model': './tmp_2019_3_23/ontonotes/nhl3_nte15_nbs64/weights_epoch03.pt',
            'override_output': True,
            'tensorboardWriter': False
            }

def set_server_eval_4CWS_param():
    return {'task_name': 'ontonotes_CWS',
            'model_type': 'sequencelabeling',
            'data_dir': '../data/CWS/',
            'vocab_file': '../models/bert-base-chinese/vocab.txt',
            'bert_config_file': '../models/bert-base-chinese/bert_config.json',
            'output_dir': './tmp_2019_3_22/out/4CWS/',
            'do_lower_case': True,
            'train_batch_size': 128,
            'max_seq_length': 128,
            'num_hidden_layers': 3,
            'init_checkpoint': '../models/bert-base-chinese/',
            'bert_model': './tmp_2019_3_23/ontonotes/nhl3_nte15_nbs64/weights_epoch03.pt',
            'visible_device': 0,
            'override_output': True,
            'tensorboardWriter': False
            }


LOCAL_FLAG = False
LOCAL_FLAG = True
#TEST_CWS = False
TEST_ONTONOTES = True
#TEST_ONTONOTES = False
TEST_CWS = True

if __name__=='__main__':
    if TEST_ONTONOTES:
        if LOCAL_FLAG:
            kwargs = set_local_eval_ontonotes_param()
        else:
            kwargs = set_server_eval_ontonotes_param()

        args._parse(kwargs)
        eval_ontonotes(args)


    if TEST_CWS:
        if LOCAL_FLAG:
            kwargs = set_local_eval_4CWS_param()
        else:
            kwargs = set_server_eval_4CWS_param()

        args._parse(kwargs)
        eval_CWS(args)

